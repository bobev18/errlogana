{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# MILL, POND, OPP1, OPP2, FOX\n",
    "# SOPS, HQ1, BAYVIEW, FIELD1\n",
    "# Bristol720, JouleHouse, Birchwood, Leicester\n",
    "# fox, mill, pond, opp1, opp2\n",
    "ROOT_FOLDER = \"/mnt/hgfs/projlogs/Integral/Maximo_22_mar\"\n",
    "MSG_SHORT_LEN = 20 #characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.mpl_style', 'default')\n",
    "pd.set_option('plotting.matplotlib.register_converters', 'default')\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set_color_codes(\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TestError():\n",
    "\n",
    "    def __init__(self, timestamp, userid, cycleid, uj, stepid, errortype, message, test_folder):\n",
    "        self.time = pd.to_datetime(timestamp, infer_datetime_format=True) \n",
    "        self.userid = userid\n",
    "        self.cycleid = cycleid\n",
    "        self.stepid = stepid\n",
    "        self.errortype = errortype\n",
    "        self.message = message\n",
    "        self.test_folder = test_folder\n",
    "        self.uj = uj\n",
    "        \n",
    "        self.cause = ''\n",
    "        self.cause_message = ''\n",
    "        \n",
    "        if errortype == 'Success Validation Failure':\n",
    "            sv = re.search(r'failed sub validations: (.+?)\\) for step \".+?\" was not found in the response. The response received has been written to \"(.+?)\"', message)\n",
    "            self.validation = sv.group(1)\n",
    "            self.file = sv.group(2)\n",
    "            # name_parts = self.file.split('__')\n",
    "            # self.uj = name_parts[0]\n",
    "        else:\n",
    "            self.validation = None\n",
    "            self.file = None\n",
    "\n",
    "        if errortype == 'Response DD Extraction Failure':\n",
    "            ddisrc = re.search(r'Error reading value for response DD item (.+?) used in step (.+?)', message)\n",
    "            self.dditem = ddisrc.group(1)\n",
    "            # !!! the line below currently gives wrong value due to BUG in the ST logs.\n",
    "            # self.ddi_source = ddisrc.group(2)\n",
    "        else:\n",
    "            self.dditem = None\n",
    "    \n",
    "    def show(self, shorten=True):\n",
    "        if shorten:\n",
    "            message = self.cause_message[:MSG_SHORT_LEN] + (len(self.cause_message)>MSG_SHORT_LEN)*'...'\n",
    "        if self.dditem:\n",
    "            message = self.dditem\n",
    "        return OrderedDict([('time', self.time),\n",
    "                ('user', self.userid),\n",
    "#                 ('total errors', 0),\n",
    "                ('uj', self.uj),\n",
    "                ('step', self.stepid),\n",
    "                ('cycle', self.cycleid),\n",
    "                ('error type', self.errortype),\n",
    "                ('error cause', self.cause),\n",
    "                ('cause message/ddi', self.cause_message),\n",
    "               ])\n",
    "    \n",
    "    def set_snapshot_details(self):\n",
    "        pass\n",
    "        \n",
    "    def _read_error_file(self):\n",
    "        if self.errortype == 'Success Validation Failure':\n",
    "            try:\n",
    "                # for QR, log files are directly in the log folder for the run\n",
    "                with open(os.path.join(self.test_folder, self.file), 'rt') as f:\n",
    "                    html = f.read()\n",
    "            except FileNotFoundError:\n",
    "                # for non-QR, log files are in subfolders named after virtual user ids\n",
    "                with open(os.path.join(self.test_folder, 'user'+self.userid , self.file), 'rt') as f:\n",
    "                    html = f.read()\n",
    "\n",
    "        return html\n",
    "    \n",
    "    def _set_cause(self, cause, message):\n",
    "        self.cause = cause\n",
    "        self.cause_message = message\n",
    "        \n",
    "    def determine_casuse(self):\n",
    "        if self.errortype == 'Success Validation Failure':\n",
    "            html = self._read_error_file()\n",
    "            if html.count('<label for=\"username\">User Name:</label>')>0:\n",
    "                self._set_cause('logged off', '')\n",
    "                return None\n",
    "\n",
    "            kick_match = re.search(r'redirect><\\!\\[CDATA\\[https*://.+?/maximo/webclient/login/logout.jsp.*?\\]\\]></redirect>', html)\n",
    "            if kick_match is not None:\n",
    "                self._set_cause('Maximo forcefully signed out the user', '')\n",
    "                return None\n",
    "\n",
    "            if html.count('title=\"Please wait...\">Please wait...</label>')>0:\n",
    "                self._set_cause('Long Op', '')\n",
    "                return None\n",
    "            \n",
    "            if html.count(\"addLongOpTimeout('dolongopquerycheck()',\")>0:\n",
    "                self._set_cause('Long Op', '')\n",
    "                return None\n",
    "\n",
    "            if html.count('MessageWarning.png')>0:\n",
    "                msg = html[html.find('MessageWarning.png'):]\n",
    "                msg = '<' + msg[:msg.find('</table>')]\n",
    "                msg = re.sub(r'<[^>]*?>', '', msg)\n",
    "                msg = msg.replace('\\n','').strip()\n",
    "                self._set_cause('Warning Message', msg)\n",
    "                return None\n",
    "\n",
    "            if html.count('st_MessageQuestion.png')>0:\n",
    "                msg = html[html.find('st_MessageQuestion.png'):]\n",
    "                msg = '<' + msg[:msg.find('</table>')]\n",
    "                msg = re.sub(r'<[^>]*?>', '', msg)\n",
    "                msg = msg.replace('\\n','').strip()\n",
    "                self._set_cause('Question Message', msg)\n",
    "                return None\n",
    "            \n",
    "            if html.count('st_MessageCritical.png')>0:\n",
    "                msg = html[html.find('st_MessageCritical.png'):]\n",
    "                msg = '<' + msg[:msg.find('</table>')]\n",
    "                msg = msg[:msg.find('</component>')]                \n",
    "                msg = re.sub(r'<[^>]*?>', '', msg)\n",
    "                msg = msg.replace('\\n','').strip()\n",
    "                self._set_cause('Critical Message', msg)\n",
    "                return None\n",
    "\n",
    "            if html.count('>0 - 0 of 0')>0:\n",
    "                self._set_cause('operation resulted in a table with zero rows', 'searchterm: ' + self.validation)\n",
    "                return None\n",
    "\n",
    "            break_index = html.find('---------------Response-----------------')\n",
    "            html_request_only = html[:break_index]\n",
    "            html_response_only = html[break_index + 40:]\n",
    "            if html_response_only.count(self.validation)>0:\n",
    "                self._set_cause('validation bug', 'searchterm: ' + self.validation)\n",
    "                return None\n",
    "\n",
    "            ###  --- COB specific errors ---\n",
    "            if  html_response_only.count('\"id\":\"0_APPRSS_OPTION\",\"text\":\"APPRSS\"') and not html_response_only.count('Approved'):\n",
    "                self._set_cause('missing \"Approved\" option', '')\n",
    "                return None\n",
    "\n",
    "            if html_request_only.count('targetId%22%3A%22mx387') and html_response_only.count('title=\"1 - 2 of 2\">1 - 2'):\n",
    "                self._set_cause('dynamic response', 'missing reference of WO field, thus cant validate')\n",
    "                return None\n",
    "\n",
    "            if html_request_only.count('<command>ISWM-RECORDFAILUREREPORT</command>'):\n",
    "                self._set_cause('response lacks confirmation of recordid', 'response lacks confirmation of recordid')\n",
    "                return None   \n",
    "            ### --- ==================== ---\n",
    "            \n",
    "            ###  --- Integral specific errors ---\n",
    "            if  html_response_only.count('The PPM & Work Order Billing Process has now been initiated.') and \\\n",
    "                                                    not html_response_only.count('Record has been saved.'):\n",
    "                self._set_cause('new Wrokflow response',\n",
    "                    'received \"The PPM & Work Order Billing Process has now been initiated.\" instead of \"Record has been saved.\"')\n",
    "                return None\n",
    "            \n",
    "            if  html_response_only.count('>Do nothing</label>') and html_response_only.count('>Cancel the bill</label>'):\n",
    "                self._set_cause('new Wrokflow response', 'received radio buttons \"Do nothing\" and \"Cancel the bill\"')\n",
    "                return None\n",
    "            ### --- ==================== ---\n",
    "            \n",
    "            self._set_cause('unknown validation fail', html_response_only)\n",
    "            self.html = html\n",
    "        else:\n",
    "            self._set_cause(self.errortype, '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Loop():\n",
    "    \n",
    "    def __init__(self, lead_error, lenght):\n",
    "        # the start & end index, should refer to cycle index, not error index\n",
    "        self.lead_error = lead_error\n",
    "        self.start = int(lead_error.cycleid)\n",
    "        self.end = self.start + lenght\n",
    "        # the +1 is needed because both the starter and the final cycles are part of the loop\n",
    "        # it shouldn't be passed in the constructor in order to properly calculate the end cycle id\n",
    "        self.lenght = lenght + 1\n",
    "        \n",
    "    def show(self):\n",
    "        return OrderedDict([('loop start', self.start), ('loop length', self.lenght),])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.start) + '-' + str(self.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VirtualUser():\n",
    "    \n",
    "    def __init__(self, userid, start_time, uj, errors=[], loops=[], max_loop=None):\n",
    "        self.userid = userid\n",
    "        self.start_time = start_time\n",
    "        self.uj = uj\n",
    "        self.errors = errors\n",
    "        self.loops = loops\n",
    "        self.max_loop = max_loop\n",
    "        \n",
    "    # If I can user.errors.append(err) , why create a method?\n",
    "    def append_error(self, error):\n",
    "        self.errors.append(error)\n",
    "\n",
    "    def process_errors(self):\n",
    "        self.error_count = len(self.errors)\n",
    "        \n",
    "        consecutive_count = 0\n",
    "        consecutiveness = ''\n",
    "        max_consecutive = -1\n",
    "        max_loop = -1\n",
    "        # looping over errors in reverse, thus init with values of the last error in the list\n",
    "        prior_error = self.errors[-1]\n",
    "        for error in reversed(self.errors):\n",
    "            error.determine_casuse()\n",
    "\n",
    "            # the 1st condition needs <= instead of == because there could be multiple errors per cycleid\n",
    "            # the 2nd condoition is to avoid counting the initial record as a consecutive term\n",
    "            if int(prior_error.cycleid) - int(error.cycleid) <= 1 and error != self.errors[-1]:\n",
    "                consecutive_count += 1\n",
    "            else:\n",
    "                if consecutive_count > 0:\n",
    "                    new_loop = Loop(prior_error, consecutive_count)\n",
    "                    self.loops.append(new_loop)\n",
    "                    consecutiveness = ';' + str(new_loop) + consecutiveness\n",
    "\n",
    "                    # update max_loop\n",
    "                    if consecutive_count > max_consecutive:\n",
    "                        max_consecutive = consecutive_count\n",
    "                        self.max_loop = new_loop\n",
    "\n",
    "                consecutive_count = 0\n",
    "                \n",
    "            prior_error = error\n",
    "        \n",
    "        # check if the for-ending error was completing an error-loop\n",
    "        if consecutive_count > 0:\n",
    "            new_loop = Loop(prior_error, consecutive_count)\n",
    "            self.loops.append(new_loop)\n",
    "            consecutiveness = ';' + str(new_loop) + consecutiveness\n",
    "\n",
    "            # update max_loop\n",
    "            if consecutive_count > max_consecutive:\n",
    "                max_consecutive = consecutive_count\n",
    "                self.max_loop = new_loop\n",
    "        \n",
    "        self._process_cause_stats()\n",
    "        \n",
    "        return consecutiveness[1:]\n",
    "    \n",
    "    def _process_cause_stats(self):\n",
    "        causes = {}\n",
    "        for e in self.errors:\n",
    "            if e.cause in causes.keys():\n",
    "                causes[e.cause] += 1\n",
    "            else:\n",
    "                causes[e.cause] = 1\n",
    "\n",
    "        self.causes = causes\n",
    "        \n",
    "    def lead_error_info(self, shorten=True):\n",
    "        # return info on the \"lead\" error of the longest error-loop\n",
    "        #   or the first error for the user\n",
    "        \n",
    "        if self.max_loop:\n",
    "            lead_error_info = self.max_loop.lead_error.show(shorten=shorten)\n",
    "            max_loop_info = self.max_loop.show()\n",
    "        else:\n",
    "            lead_error_info = self.errors[0].show(shorten=shorten)\n",
    "            max_loop_info = OrderedDict([('loop start', ''), ('loop length', '')])\n",
    "            \n",
    "        def surgery(ordered_dict, index, insertion):\n",
    "            return OrderedDict(list(ordered_dict.items())[:index] + \n",
    "                               list(insertion.items()) + \n",
    "                               list(ordered_dict.items())[index:])\n",
    "        \n",
    "        lead_error_info = surgery(lead_error_info, 2, {'total errors': user.error_count})\n",
    "        lead_error_info = surgery(lead_error_info, -2, max_loop_info)\n",
    "            \n",
    "        return lead_error_info\n",
    "    \n",
    "    def get_errors(self, shorten=True):\n",
    "        result = pd.DataFrame([ z.show(shorten=shorten) for z in self.errors ])\n",
    "        result.index = pd.to_datetime(result.time, errors='coerce')\n",
    "        result.drop(columns=['time'])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the graph functionality should not be tied in the classes; plotting should decouple from DF resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def groupby_resample(udf, feature, freq='H'):\n",
    "    tmpdf = pd.DataFrame()\n",
    "    tmpdf[feature] = udf[feature]\n",
    "    ndf = tmpdf.groupby(feature).resample(freq).count().unstack(feature)\n",
    "    return ndf\n",
    "    # ndf.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeslice(df, start=None, end=None):\n",
    "    # \n",
    "    if start and isinstance(start, str):\n",
    "        start = pd.to_datetime(start, errors='coerce')\n",
    "    if end and isinstance(end, str):\n",
    "        end = pd.to_datetime(end, errors='coerce')\n",
    "    if start and end:\n",
    "        ndf = df[start:end]\n",
    "    elif start and not end:\n",
    "        ndf = df[start:]\n",
    "    elif end and not start:\n",
    "        ndf = df[:end]\n",
    "    else:\n",
    "        ndf = df[:]\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bar_categorical(udf, feature, freq='H', figsize=(12,8), title=None):\n",
    "    tmpdf = pd.DataFrame()\n",
    "    tmpdf[feature] = udf[feature]\n",
    "    ndf = tmpdf.groupby(feature).resample(freq).count().unstack(feature)\n",
    "    ndf.plot.bar(stacked=True, figsize=figsize)\n",
    "    if title:\n",
    "        plt.title(title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pickles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the number of relevant injector folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_folder = ROOT_FOLDER\n",
    "\n",
    "## Considered running simultaneous analisys of different injectors:\n",
    "##    it will not work, because user ids are repeated i.e user 0006 on INJ1 will be assigned to UJ1,\n",
    "##    while user 0006 on INJ2 will have different UJ, and different errors, and etc.\n",
    "\n",
    "folders = [ f for f in os.listdir(test_folder) if os.path.isdir(os.path.join(test_folder,f)) ]\n",
    "print('at', test_folder, ', found', len(folders), 'injector folders: ', folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of multiple log files, merge them and work with the merged file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(folders)>1:\n",
    "    print('multiple injectors found - loading pickeles:')\n",
    "    injectors = {}\n",
    "    for inj_folder in folders:\n",
    "        injectors[inj_folder] = pickle.load(open(os.path.join(test_folder, inj_folder, 'with_loops.pickle'), 'rb'))\n",
    "        print('injector', inj_folder, 'reports', len(injectors[inj_folder]), 'erroring users')\n",
    "else:\n",
    "    print('one or no folders found - exiting')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall injector stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vusers = pickle.load(open(os.path.join(test_folder, 'with_loops.pickle'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "causes = {}\n",
    "causes_keys = []\n",
    "accu = []\n",
    "for inj in folders:\n",
    "    sorted_keys = sorted(injectors[inj].keys())\n",
    "    for userid in sorted_keys:\n",
    "        user = injectors[inj][userid]\n",
    "        errors_values = list(user.lead_error_info(shorten=False).values())\n",
    "        all_user_errors = user.get_errors(shorten=False)\n",
    "#         unknowns = all_user_errors.loc[all_user_errors['error cause'] == 'unknown validation fail']\n",
    "#         if len(unknowns):\n",
    "#             print('   >>>', inj, userid)\n",
    "#             display(unknowns)\n",
    "#         crits = all_user_errors.loc[all_user_errors['error cause'] == 'Critical Message']\n",
    "#         if len(crits):\n",
    "#             print('   >>>', inj, userid)\n",
    "#             display(crits)\n",
    "#         nwfr = all_user_errors.loc[all_user_errors['error cause'] == 'new Wrokflow response']\n",
    "#         if len(nwfr):\n",
    "#             print('   >>>', inj, userid)\n",
    "#             display(nwfr)\n",
    "\n",
    "        accu.append([inj] + errors_values)\n",
    "        for val in errors_values:\n",
    "            try:\n",
    "                print(val[:250], end=',')\n",
    "            except TypeError:\n",
    "                print(val, end=',')\n",
    "        print()\n",
    "        if causes_keys == []:\n",
    "            causes_keys = list(user.lead_error_info(shorten=False))\n",
    "\n",
    "        # summation of values of corresponding key over list of dicts\n",
    "        for key in user.causes.keys():\n",
    "            causes[key]=causes.setdefault(key, 0) + user.causes[key]\n",
    "\n",
    "data = pd.DataFrame(accu, columns=['inj'] + causes_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 9999\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info on the \"lead\" errors for the longest error-loop or, if no error-loop, the first error for the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat = list(causes.items())\n",
    "stats = [ z[1] for z in cat ]\n",
    "types = [ z[0] for z in cat ]\n",
    "types[1] = 'loop error'\n",
    "# cdf = pd.DataFrame(stats, index=types, columns=['cause type'])\n",
    "cdft = pd.DataFrame([stats], index=['count'], columns=types)\n",
    "# cdf.plot.bar(figsize=(12,8));\n",
    "# the_table = plt.table(cellText=[stats], loc='top') #rowLabels= ['cause type'],\n",
    "# the_table.set_fontsize(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdft.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,8))\n",
    "sns.barplot(data=cdft);\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "the_table = plt.table(cellText=[stats], loc='top') #rowLabels= ['cause type'],\n",
    "the_table.set_fontsize(14)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,8))\n",
    "sns.barplot(data=cdft[list(filter(lambda x: x!= 'loop error', types))], palette=\"Set3\");\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "the_table = plt.table(cellText=[[stats[0]]+stats[2:]], loc='top') #rowLabels= ['cause type'],\n",
    "the_table.set_fontsize(14)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['error cause'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nwfr = data.loc[data['error cause'] == 'new Wrokflow response']\n",
    "nwfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of individual virtual users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FAIL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute(\"URL = '\" + window.location + \"'\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid = URL.split('?')[1].split('=')[1]\n",
    "errs9 = vusers[uid].get_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid='0005'\n",
    "errs9 = vusers[uid].get_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# shorten the cause message\n",
    "errs9['cause message/ddi'] = errs9['cause message/ddi'].apply(lambda x: x[:50])\n",
    "bar_categorical(errs9, 'error type', 'T', figsize=(15,9), title=uid + '_' + vusers[uid].uj);\n",
    "bar_categorical(errs9, 'cause message/ddi', 'T', figsize=(15,9));\n",
    "bar_categorical(errs9, ['step'], 'T', figsize=(15,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 9999\n",
    "display(errs9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf = timeslice(errs9, datetime(2018, 1, 29, 9, 41, 26), datetime(2018, 1, 29, 9, 41, 27))\n",
    "print(sdf)\n",
    "sdf = timeslice(errs9, '2018-1-29T9:41:26', '2018-1-29T9:41:27')\n",
    "print(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# errs9['2018-1-29 9:41']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html#Resampling-and-converting-frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vusers['0005'].errors[0].show() # shorten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user 5 (or 7) on SOPS:: \n",
    "BMXAA8229W - Record WORKORDER :  Site=WW Work Order=4880902 has been updated by another user. Your changes have not been saved. Refresh the record and try again.\n",
    "\n",
    "user 4 on BAYVIEW:\n",
    "BMXAA8229W - Record WORKORDER :  Site=WW Work Order=4880921 has been updated by another user. Your changes have not been saved. Refresh the record and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FAIL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be working. The key factors are:\n",
    "* errors='coerce'\n",
    "* udf.index = \n",
    "* lookup references should be done by range of datetimes !\n",
    "\n",
    "The double rows for column names is rather a quirk of the \"pretty print\" in Jupyter, since `udf.columns.nlevels` returns 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "udf = errs9\n",
    "udf.columns.nlevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pandas.tseries import converter as pdtc\n",
    "# import matplotlib.units as munits\n",
    "# import numpy as np\n",
    "\n",
    "# munits.registry[np.datetime64] = pdtc.DatetimeConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotit(df, plot_params):\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # ax2 = ax1.twinx()\n",
    "    ax1.plot(df.index, df['user'], 'b-')\n",
    "    # ax2.plot(df.index, df['distance'], 'b-')\n",
    "\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Errors', color='b')\n",
    "    # ax2.set_ylabel('Distance', color='g')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    plt.rcParams['figure.figsize'] = 15,9\n",
    "    # df.plot(**plot_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "period = 'h'\n",
    "plot_params = {'kind': 'bar', 'title' : 'errors per ' + period, 'figsize': (15, 9) }#  'style': ['-.'], }\n",
    "plotit(udf, plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf = pd.DataFrame()\n",
    "hdf['user'] = udf.user.resample('H').count()\n",
    "hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotit(hdf, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def barit(df, bar_width_apparently_in_days=0.04):\n",
    "    \n",
    "    print('bar width:', bar_width_apparently_in_days)\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # ax2 = ax1.twinx()\n",
    "    ax1.bar(df.index, df['user'], width=bar_width_apparently_in_days, color='b') #, ec='r')\n",
    "    # ax2.plot(df.index, df['distance'], 'b-')\n",
    "\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Errors', color='b')\n",
    "    # ax2.set_ylabel('Distance', color='g')\n",
    "    \n",
    "    #set ticks every week\n",
    "    if bar_width_apparently_in_days > 0.001:\n",
    "        ax1.xaxis.set_major_locator(mdates.HourLocator())\n",
    "    else:\n",
    "        ax1.xaxis.set_major_locator(mdates.MinuteLocator(interval=15))\n",
    "    \n",
    "    #set major ticks format\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    plt.rcParams['figure.figsize'] = 15,9\n",
    "    # df.plot(**plot_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barit(hdf, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdf = pd.DataFrame()\n",
    "mdf['user'] = udf.user.resample('T').count()\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barit(mdf, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barit(mdf, 0.0006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barit(mdf[datetime(2018, 1, 29, 6):], 0.0003) #datetime(2018, 1, 29, 9, 41, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barit(mdf[datetime(2018, 1, 29, 6, 40):datetime(2018, 1, 29, 7, 40)], 0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Seaborn /sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(hdf.index, hdf.user, color=\"b\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,8))\n",
    "sns.countplot('error type', data=udf) #, size=6, aspect=1.5)#, ax=ax[0,0])\n",
    "# sns.factorplot( x=udf.user, data=udf, kind=\"count\", size=6, aspect=1.5)#, ax=ax[0,0])\n",
    "# ax.set_xticklabels('errors') #, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "udf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf = pd.DataFrame()\n",
    "hdf['user'] = udf.user.resample('H').count()\n",
    "hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmpdf = pd.DataFrame()\n",
    "tmpdf['error type'] = udf['error type']\n",
    "tmpdf['cycle'] = udf['cycle'].astype(int)\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \".groupby\" works as follows: creates sor of \"dictionary\" (DataFrameGroupBy object) with keys matching the groups, and each value in the dictionary is a DataFrame with the corresponding rows from the original DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_df = tmpdf.groupby('error type')\n",
    "for key, item in grouped_df:\n",
    "    print(grouped_df.get_group(key), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a function to the DataFrameGroupBy object, causes it to be \"reduced\" to a regular DataFrame - prior dict keys are now indexes and the rows values are collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summed = grouped_df.sum()\n",
    "print(type(summed))\n",
    "summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying `.resample(<period_encoding>)`, generally results in object that cannot be directly viewed (yet has index). Only after applyng additional function, the resulting object is a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resampled = tmpdf.resample('H')\n",
    "print(resampled.index)\n",
    "# resampled.loc[resampled.index[0]]\n",
    "# resampled.iloc[0]\n",
    "\n",
    "resampled_mean = tmpdf.resample('H').mean()\n",
    "resampled_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying `.resample()` on top of a grouped object, gives a DatetimeIndexResamplerGroupby object. The key difference is that now there is MuliIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resampled = grouped_df.resample('H')\n",
    "print(resampled.index)\n",
    "resampled_mean = grouped_df.resample('H').mean()\n",
    "resampled_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndf = tmpdf.groupby('error type').resample('H').count().unstack('error type')\n",
    "ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above case where we used the cycle as nummeric value is not ideal - changing to just error_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmpdf = pd.DataFrame()\n",
    "tmpdf['error type'] = udf['error type']\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `.unstack()` \"pivots\" the index based on the error_type values to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndf = tmpdf.groupby('error type').resample('H').count().unstack('error type')\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndf.plot.bar(stacked=True, label='proba');\n",
    "plt.title(\"Colors vs Values\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bar_categorical2(udf, feature, freq='H', figsize=(12,8), title=None):\n",
    "    tmpdf = pd.DataFrame()\n",
    "    tmpdf[feature] = udf[feature]\n",
    "    ndf = tmpdf.groupby(feature).resample(freq).count().unstack(feature)\n",
    "    \n",
    "#     f, ax = plt.subplots(figsize=(12,8));\n",
    "#     sns.countplot('error type', data=ndf,)# stacked=True)\n",
    "    ndf.plot.bar(stacked=True);\n",
    "    if title:\n",
    "        plt.title(title);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "udf = vusers['0007'].get_errors()\n",
    "udf.index = pd.to_datetime(udf.time, errors='coerce')\n",
    "bar_categorical2(udf, 'error type', '15T', title='Proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar_categorical(udf, 'step', '15T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar_categorical(udf, 'cause message/ddi', '15T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
